# DoctorFollow Medical Search Agent - Environment Variables
# Copy this file to .env and fill in your credentials

# ============================================
# LLM Provider (OpenAI or AWS Bedrock)
# ============================================
LLM_PROVIDER=openai
# LLM_PROVIDER=bedrock

# OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key-here

# AWS Bedrock (for LLM) - backup
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=your-aws-access-key-here
AWS_SECRET_ACCESS_KEY=your-aws-secret-key-here

# ============================================
# Database Connections (match docker-compose.yml)
# ============================================

# OpenSearch
OPENSEARCH_HOST=localhost
OPENSEARCH_PORT=9200

# PostgreSQL + pgvector
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=doctorfollow
POSTGRES_USER=doctor
POSTGRES_PASSWORD=follow123

# Neo4j
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=doctorfollow123

# ============================================
# Model Configuration
# ============================================

# LLM Model
OPENAI_MODEL=gpt-4o-mini
# OPENAI_MODEL=gpt-4o (more powerful but costs more)

BEDROCK_MODEL_ID=us.meta.llama4-scout-17b-instruct-v1:0

# Embedding Model (multilingual for Turkish â†” English)
# Options:
#   - intfloat/multilingual-e5-large (1024 dim, best quality)
#   - intfloat/multilingual-e5-base (768 dim, faster)
#   - intfloat/multilingual-e5-small (384 dim, fastest)
EMBEDDING_MODEL=intfloat/multilingual-e5-small
EMBEDDING_DIMENSION=384

# ============================================
# RAG Parameters
# ============================================

# Chunking
CHUNK_SIZE=500
CHUNK_OVERLAP=100

# Retrieval
TOP_K_OPENSEARCH=5
TOP_K_PGVECTOR=5
TOP_K_FINAL=3
RRF_K=60

# LLM Generation
LLM_TEMPERATURE=0.2
LLM_MAX_TOKENS=512
